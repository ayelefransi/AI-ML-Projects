{"cells":[{"cell_type":"code","source":["# Import required libraries\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications.resnet import ResNet50\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense, Input, BatchNormalization, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n","from tqdm import tqdm\n","import itertools\n","import seaborn as sns\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Data preparation\n","data_dir = ('/content/drive/MyDrive/brain_tumour/Training')\n","categories = ['glioma', 'meningioma', 'notumor', 'pituitary']\n","plt.figure(figsize=(20, 16))\n","\n","images_path = ['/glioma/Tr-gl_0010.jpg', '/meningioma/Tr-meTr_0000.jpg', '/notumor/Tr-noTr_0000.jpg', '/pituitary/Tr-piTr_0000.jpg']\n","for i in range(4):\n","    ax = plt.subplot(2, 2, i + 1)\n","    img = cv2.imread(data_dir + images_path[i])\n","    img = cv2.resize(img, (224, 224))\n","    plt.imshow(img)\n","    plt.title(categories[i])\n","\n","# Function to crop images\n","def crop_img(img):\n","    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","    gray = cv2.GaussianBlur(gray, (3, 3), 0)\n","    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n","    thresh = cv2.erode(thresh, None, iterations=2)\n","    thresh = cv2.dilate(thresh, None, iterations=2)\n","    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    cnts = imutils.grab_contours(cnts)\n","    c = max(cnts, key=cv2.contourArea)\n","    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n","    extRight = tuple(c[c[:, :, 0].argmax()][0])\n","    extTop = tuple(c[c[:, :, 1].argmin()][0])\n","    extBot = tuple(c[c[:, :, 1].argmax()][0])\n","    ADD_PIXELS = 0\n","    new_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()\n","    return new_img\n","\n","# Load and preprocess data\n","labels = ['glioma', 'meningioma', 'notumor', 'pituitary']\n","x_train, y_train, x_test, y_test = [], [], [], []\n","image_size = 200\n","\n","for label in labels:\n","    trainPath = os.path.join('/content/drive/My Drive/brain_tumour/cropped/Training', label)\n","    for file in tqdm(os.listdir(trainPath)):\n","        image = cv2.imread(os.path.join(trainPath, file), 0)\n","        image = cv2.bilateralFilter(image, 2, 50, 50)\n","        image = cv2.applyColorMap(image, cv2.COLORMAP_BONE)\n","        image = cv2.resize(image, (image_size, image_size))\n","        x_train.append(image)\n","        y_train.append(labels.index(label))\n","\n","    testPath = os.path.join('/content/drive/My Drive/brain_tumour/cropped/Testing', label)\n","    for file in tqdm(os.listdir(testPath)):\n","        image = cv2.imread(os.path.join(testPath, file), 0)\n","        image = cv2.bilateralFilter(image, 2, 50, 50)\n","        image = cv2.applyColorMap(image, cv2.COLORMAP_BONE)\n","        image = cv2.resize(image, (image_size, image_size))\n","        x_test.append(image)\n","        y_test.append(labels.index(label))\n","\n","x_train = np.array(x_train) / 255.0\n","x_test = np.array(x_test) / 255.0\n","\n","x_train, y_train = shuffle(x_train, y_train, random_state=42)\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)\n","\n","x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n","\n","# Image Augmentation\n","datagen = ImageDataGenerator(rotation_range=10, width_shift_range=0.05, height_shift_range=0.05, horizontal_flip=True)\n","datagen.fit(x_train)\n","\n","# Build and compile ResNet50 model\n","IMG_SIZE = (200, 200)\n","conv_base = ResNet50(include_top=False, input_shape=IMG_SIZE + (3,), weights='imagenet')\n","for layer in conv_base.layers:\n","    layer.trainable = True\n","\n","model = conv_base.output\n","model = GlobalAveragePooling2D()(model)\n","model = Dropout(0.4)(model)\n","model = Dense(4, activation=\"softmax\")(model)\n","model = Model(inputs=conv_base.input, outputs=model)\n","\n","adam = Adam(learning_rate=0.0001)\n","model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","callbacks = [\n","    ModelCheckpoint('.mdl_wts.hdf5', monitor='val_loss', mode='min', verbose=1, save_best_only=True),\n","    ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=1, mode='min', min_lr=1e-10)\n","]\n","\n","history = model.fit(datagen.flow(x_train, y_train, batch_size=64), validation_data=(x_val, y_val), epochs=50, callbacks=callbacks)\n","\n","# Plot Loss and Accuracy curves\n","plt.figure(figsize=[8, 6])\n","plt.plot(history.history['loss'], 'r', linewidth=3.0)\n","plt.plot(history.history['val_loss'], 'b', linewidth=3.0)\n","plt.legend(['Training loss', 'Validation Loss'], fontsize=18)\n","plt.xlabel('Epochs ', fontsize=16)\n","plt.ylabel('Loss', fontsize=16)\n","plt.title('Loss Curves', fontsize=16)\n","plt.show()\n","\n","plt.figure(figsize=[8, 6])\n","plt.plot(history.history['accuracy'], 'r', linewidth=3.0)\n","plt.plot(history.history['val_accuracy'], 'b', linewidth=3.0)\n","plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=18)\n","plt.xlabel('Epochs ', fontsize=16)\n","plt.ylabel('Accuracy', fontsize=16)\n","plt.title('Accuracy Curves', fontsize=16)\n","plt.show()\n","\n","# Load best model and evaluate on test set\n","model = load_model('.mdl_wts.hdf5')\n","model.save('/content/drive/My Drive/brain_tumour/modelres50.h5')\n","model = load_model('/content/drive/My Drive/brain_tumour/modelres50.h5')\n","\n","loss, acc = model.evaluate(x_test, y_test)\n","\n","# Classification Report and Confusion Matrix\n","predicted_classes = np.argmax(model.predict(x_test), axis=1)\n","print(classification_report(np.argmax(y_test, axis=1), predicted_classes, target_names=['glioma', 'meningioma', 'no_tumor', 'pituitary']))\n","\n","rounded_labels = np.argmax(y_test, axis=1)\n","confusion_mtx = confusion_matrix(rounded_labels, predicted_classes)\n","\n","def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","\n","plot_confusion_matrix(confusion_mtx, classes=range(4))\n","\n","# ROC Curve\n","n_classes = 4\n","pred_Y = model.predict(x_test, batch_size=16, verbose=True)\n","fpr, tpr, roc_auc = dict(), dict(), dict()\n","\n","for i in range(n_classes):\n","    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], pred_Y[:, i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), pred_Y.ravel())\n","roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","\n","for i in range(n_classes):\n","    plt.figure()\n","    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n","    plt.plot([0, 1], [0, 1], 'k--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title(f'ROC Curve for Class {i}')\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n","\n","# U-Net model for segmentation\n","def unet_model():\n","    inputs = Input((128, 128, 1))\n","    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n","    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n","    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n","    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n","    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n","    drop4 = Dropout(0.5)(conv4)\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(pool4)\n","    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(conv5)\n","    drop5 = Dropout(0.5)(conv5)\n","    up6 = Conv2D(512, (2, 2), activation='relu', padding='same')(Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(drop5))\n","    merge6 = concatenate([drop4, up6], axis=3)\n","    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(merge6)\n","    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv6)\n","    up7 = Conv2D(256, (2, 2), activation='relu', padding='same')(Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6))\n","    merge7 = concatenate([conv3, up7], axis=3)\n","    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(merge7)\n","    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)\n","    up8 = Conv2D(128, (2, 2), activation='relu', padding='same')(Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7))\n","    merge8 = concatenate([conv2, up8], axis=3)\n","    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(merge8)\n","    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)\n","    up9 = Conv2D(64, (2, 2), activation='relu', padding='same')(Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8))\n","    merge9 = concatenate([conv1, up9], axis=3)\n","    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(merge9)\n","    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv9)\n","    conv9 = Conv2D(2, (3, 3), activation='relu', padding='same')(conv9)\n","    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n","    model = Model(inputs, conv10)\n","    model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Loss and Metric for U-Net\n","def bce_dice_loss(y_true, y_pred):\n","    loss = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred) + dice_loss(y_true, y_pred)\n","    return loss\n","\n","def dice_loss(y_true, y_pred):\n","    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n","    denominator = tf.reduce_sum(y_true + y_pred)\n","    return 1 - numerator / denominator\n","\n","# Load data for segmentation\n","def load_data(data_dir, img_size):\n","    images = []\n","    masks = []\n","    for img_file in os.listdir(data_dir):\n","        img_path = os.path.join(data_dir, img_file)\n","        mask_path = img_path.replace('images', 'masks')\n","        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n","        img = cv2.resize(img, img_size)\n","        mask = cv2.resize(mask, img_size)\n","        images.append(img)\n","        masks.append(mask)\n","    images = np.array(images).reshape(-1, img_size[0], img_size[1], 1) / 255.0\n","    masks = np.array(masks).reshape(-1, img_size[0], img_size[1], 1) / 255.0\n","    return images, masks\n","\n","train_images, train_masks = load_data('/content/drive/My Drive/brain_tumour/images/train', (128, 128))\n","val_images, val_masks = load_data('/content/drive/My Drive/brain_tumour/images/val', (128, 128))\n","\n","# Training U-Net model\n","seg_model = unet_model()\n","seg_model.fit(train_images, train_masks, validation_data=(val_images, val_masks), epochs=50, batch_size=16, callbacks=callbacks)\n","\n","# Save U-Net model\n","seg_model.save('/content/drive/My Drive/brain_tumour/unet_model.h5')\n","\n","# Function to segment and classify an image\n","def segment_and_classify(image):\n","    image_resized = cv2.resize(image, (128, 128))\n","    image_resized = np.expand_dims(image_resized, axis=0)\n","    mask = seg_model.predict(image_resized)\n","    mask = mask[0, ..., 0] > 0.5\n","\n","    segmented_image = image * mask[..., np.newaxis]\n","    segmented_image = cv2.resize(segmented_image, (200, 200))\n","    segmented_image = np.expand_dims(segmented_image, axis=0)\n","    segmented_image = tf.keras.applications.resnet50.preprocess_input(segmented_image)\n","\n","    preds = model.predict(segmented_image)\n","    class_idx = np.argmax(preds)\n","\n","    return class_idx, preds\n","\n","# Test the function\n","image = cv2.imread('/path/to/test_image.jpg')\n","class_idx, preds = segment_and_classify(image)\n","print(f\"Predicted class: {labels[class_idx]}\")\n"],"metadata":{"id":"BcXP_xBU9xNJ"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}